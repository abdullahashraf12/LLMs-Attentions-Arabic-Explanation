<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <link rel="icon" href="./favicon.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Jersey+10&display=swap" rel="stylesheet" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Transformer Explainer: LLM Transformer Model Visually Explained</title>

    <!-- Primary Meta Tags -->
    <meta name="title" content="Transformer Explainer: LLM Transformer Model Visually Explained" />
    <meta name="description" content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT." />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://poloclub.github.io/transformer-explainer/" />
    <meta property="og:title" content="Transformer Explainer: LLM Transformer Model Visually Explained" />
    <meta property="og:description" content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT." />
    <meta property="og:image" content="https://poloclub.github.io/transformer-explainer/preview/summary.png" />

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="https://poloclub.github.io/transformer-explainer/" />
    <meta property="twitter:title" content="Transformer Explainer: LLM Transformer Model Visually Explained" />
    <meta property="twitter:description" content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT." />
    <meta property="twitter:image" content="https://poloclub.github.io/transformer-explainer/preview/summary.png" />


    <link href="/transExP/_app/immutable/assets/Katex.CbsiBf5l.css" rel="stylesheet">
    <link href="/transExP/_app/immutable/assets/0.CO8a7wGx.css" rel="stylesheet">
    <link href="/transExP/_app/immutable/assets/2.D8EW9tW5.css" rel="stylesheet">
    <link rel="modulepreload" href="/transExP/_app/immutable/entry/start.CeaJo41a.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/chunks/CgrdHqMZ.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/chunks/5qYAIP7a.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/chunks/BhTa4PsT.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/entry/app.Bp1a5M9n.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/chunks/IHki7fMi.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/nodes/0.BGj4qG9m.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/chunks/CCRyRI5u.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/chunks/of31ZtOQ.js">
    <link rel="modulepreload" href="/transExP/_app/immutable/nodes/2.DhCMUn9M.js">
    <!-- HEAD_svelte-1bw9n98_START -->
    <!-- HEAD_svelte-1bw9n98_END -->
    <!-- HEAD_svelte-r30au3_START -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <!-- HEAD_svelte-r30au3_END -->
    <style>
        /* Target the text card and all its children */
        
        .floating-container svelte-dabew1 {
            direction: rtl !important;
            text-align: right !important;
        }
        
        .card-header svelte-dabew1 {
            direction: rtl !important;
            text-align: right !important;
        }
        
        .card-body svelte-dabew1 {
            direction: rtl !important;
            text-align: right !important;
        }
        
        .carousel-slide svelte-dabew1 {
            direction: rtl !important;
            text-align: right !important;
        }
    </style>

</head>

<body data-sveltekit-preload-data="hover">
    <div style="display: contents">
        <div id="app" style="--min-screen-width:1300px;--min-column-width:22px;--predicted-color:#7E3AF2;" class="svelte-1tjcd38">
            <div id="landing" class="svelte-1tjcd38">
                <header style="transform: translateX(0px);" class="svelte-1tjcd38">
                    <div class="top-bar flex w-full items-center gap-4 px-10 py-2 pb-3 svelte-1r01wg1">
                        <div class="logo text-bold text-gray-700 svelte-1r01wg1" data-click="logo" data-svelte-h="svelte-1df1j3v">T<span class="small svelte-1r01wg1">RANSFORMER</span> E<span class="small svelte-1r01wg1">XPLAINER</span></div>
                        <div class="inputs flex grow items-center">
                            <div class="input-wrapper w-full svelte-1r01wg1">
                                <div class="input-area svelte-rpzbd3" data-click="input-area">
                                    <form class="input-form svelte-rpzbd3" data-click="input-form">
                                        <div class="inline-flex rounded-lg shadow-sm input-btn-group" role="group"><button data-click="dropdown-btn" type="button" class="select-button inline-flex shrink-0 items-center justify-center border border-s-0 border-gray-200 bg-white px-3 py-2 text-center text-xs font-medium text-gray-900 first:rounded-s-lg first:border-s last:rounded-e-lg svelte-rpzbd3">Examples<svg xmlns="http://www.w3.org/2000/svg" fill="none" color="currentColor" class="shrink-0 pointer-events-none h-4 w-4 text-gray-500" role="img" aria-label="chevron down outline" viewBox="0 0 24 24"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m8 10 4 4 4-4"></path></svg> </button>
                                            <div></div>
                                            <div data-click="text-input" class="input-container svelte-rpzbd3 disabled" role="none" style="direction: ltr !important; text-align: left;">
                                                <div class="editable w-full svelte-rpzbd3">
                                                    <div contenteditable="false" class="text-box svelte-rpzbd3" placeholder="Test your own input text" role="input">Data visualization empowers users to</div>
                                                    <div class="predicted svelte-rpzbd3" role="none"><span class="svelte-rpzbd3"></span></div>
                                                </div>
                                            </div>
                                        </div> <button data-click="generate-btn" disabled class="generate-button rounded-lg text-center text-sm shadow-sm disabled svelte-rpzbd3" type="submit">Generate</button></form>
                                    <div class="parameters svelte-rpzbd3" data-click="input-parameters">
                                        <div class="temperature-input svelte-47a5d3" data-click="temperature-input">
                                            <div class="slider-input shrink-0 text-gray-900 temperature-slider svelte-1pcv1cp">
                                                <div class="slider-head flex w-full shrink-0 items-center justify-center">
                                                    <div class="temperature-text flex items-center gap-[2px] svelte-47a5d3">
                                                        <div id="temperature" class="textbook-tooltip svelte-138miuj" data-click="textbook-tooltip" role="button" tabindex="0">
                                                            <div data-svelte-h="svelte-knfc80">Temperature</div>
                                                        </div>
                                                    </div>
                                                </div>
                                                <div class="slider-container svelte-1pcv1cp"><input class="slider svelte-1pcv1cp" type="range" min="0" max="17" step="1" value="6">
                                                    <div class="value svelte-1pcv1cp">
                                                        <p>0.8</p>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                        <div class="sampling-input svelte-19rf5er" data-click="input-sampling">
                                            <div class="slider-input shrink-0 text-gray-900 sampling-slider svelte-1pcv1cp">
                                                <div class="slider-head flex w-full shrink-0 items-center justify-center">
                                                    <div class="sampling-type svelte-19rf5er">
                                                        <div class="title flex items-center gap-[2px] svelte-19rf5er">
                                                            <div id="sampling" class="textbook-tooltip svelte-138miuj" data-click="textbook-tooltip" role="button" tabindex="0">
                                                                <div data-svelte-h="svelte-1brf1i7">Sampling</div>
                                                            </div>
                                                        </div>
                                                        <div class="sampling-type-input flex svelte-19rf5er"> <label class="text-sm rtl:text-right font-medium text-gray-900 dark:text-gray-300 inline-flex items-center type-btn"><input type="radio" value="top-k" class="w-4 h-4 bg-gray-100 border-gray-300 dark:ring-offset-gray-800 focus:ring-2 me-2 dark:bg-gray-700 dark:border-gray-600 text-purple-600 focus:ring-purple-500 dark:focus:ring-purple-600" name="sampling-type" checked> Top-k</label>                                                            <label class="text-sm rtl:text-right font-medium text-gray-900 dark:text-gray-300 inline-flex items-center type-btn"><input type="radio" value="top-p" class="w-4 h-4 bg-gray-100 border-gray-300 dark:ring-offset-gray-800 focus:ring-2 me-2 dark:bg-gray-700 dark:border-gray-600 text-purple-600 focus:ring-purple-500 dark:focus:ring-purple-600" name="sampling-type"> Top-p</label>                                                            </div>
                                                    </div>
                                                </div>
                                                <div class="slider-container svelte-1pcv1cp"><input class="slider svelte-1pcv1cp" type="range" min="1" max="50" step="1" value="5">
                                                    <div class="value svelte-1pcv1cp">
                                                        <p>k=5</p>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="icons flex items-center gap-3 svelte-1r01wg1" data-svelte-h="svelte-g137ca"> <a href="https://arxiv.org/abs/2408.04619" target="_blank" data-click="pdf-btn"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1r01wg1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M9 2.221V7H4.221a2 2 0 0 1 .365-.5L8.5 2.586A2 2 0 0 1 9 2.22ZM11 2v5a2 2 0 0 1-2 2H4a2 2 0 0 0-2 2v7a2 2 0 0 0 2 2 2 2 0 0 0 2 2h12a2 2 0 0 0 2-2 2 2 0 0 0 2-2v-7a2 2 0 0 0-2-2V4a2 2 0 0 0-2-2h-7Zm-6 9a1 1 0 0 0-1 1v5a1 1 0 1 0 2 0v-1h.5a2.5 2.5 0 0 0 0-5H5Zm1.5 3H6v-1h.5a.5.5 0 0 1 0 1Zm4.5-3a1 1 0 0 0-1 1v5a1 1 0 0 0 1 1h1.376A2.626 2.626 0 0 0 15 15.375v-1.75A2.626 2.626 0 0 0 12.375 11H11Zm1 5v-3h.375a.626.626 0 0 1 .625.626v1.748a.625.625 0 0 1-.626.626H12Zm5-5a1 1 0 0 0-1 1v5a1 1 0 1 0 2 0v-1h1a1 1 0 1 0 0-2h-1v-1h1a1 1 0 1 0 0-2h-2Z" clip-rule="evenodd"></path></svg></a>                            <a href="https://www.youtube.com/watch?v=ECR4oAwocjs" target="_blank" data-click="ytb-btn"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1r01wg1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M21.7 8.037a4.26 4.26 0 0 0-.789-1.964 2.84 2.84 0 0 0-1.984-.839c-2.767-.2-6.926-.2-6.926-.2s-4.157 0-6.928.2a2.836 2.836 0 0 0-1.983.839 4.225 4.225 0 0 0-.79 1.965 30.146 30.146 0 0 0-.2 3.206v1.5a30.12 30.12 0 0 0 .2 3.206c.094.712.364 1.39.784 1.972.604.536 1.38.837 2.187.848 1.583.151 6.731.2 6.731.2s4.161 0 6.928-.2a2.844 2.844 0 0 0 1.985-.84 4.27 4.27 0 0 0 .787-1.965 30.12 30.12 0 0 0 .2-3.206v-1.516a30.672 30.672 0 0 0-.202-3.206Zm-11.692 6.554v-5.62l5.4 2.819-5.4 2.801Z" clip-rule="evenodd"></path></svg></a>                            <a href="https://github.com/poloclub/transformer-explainer" target="_blank" data-click="github_btn"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1r01wg1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M12.006 2a9.847 9.847 0 0 0-6.484 2.44 10.32 10.32 0 0 0-3.393 6.17 10.48 10.48 0 0 0 1.317 6.955 10.045 10.045 0 0 0 5.4 4.418c.504.095.683-.223.683-.494 0-.245-.01-1.052-.014-1.908-2.78.62-3.366-1.21-3.366-1.21a2.711 2.711 0 0 0-1.11-1.5c-.907-.637.07-.621.07-.621.317.044.62.163.885.346.266.183.487.426.647.71.135.253.318.476.538.655a2.079 2.079 0 0 0 2.37.196c.045-.52.27-1.006.635-1.37-2.219-.259-4.554-1.138-4.554-5.07a4.022 4.022 0 0 1 1.031-2.75 3.77 3.77 0 0 1 .096-2.713s.839-.275 2.749 1.05a9.26 9.26 0 0 1 5.004 0c1.906-1.325 2.74-1.05 2.74-1.05.37.858.406 1.828.101 2.713a4.017 4.017 0 0 1 1.029 2.75c0 3.939-2.339 4.805-4.564 5.058a2.471 2.471 0 0 1 .679 1.897c0 1.372-.012 2.477-.012 2.814 0 .272.18.592.687.492a10.05 10.05 0 0 0 5.388-4.421 10.473 10.473 0 0 0 1.313-6.948 10.32 10.32 0 0 0-3.39-6.165A9.847 9.847 0 0 0 12.007 2Z" clip-rule="evenodd"></path></svg></a></div>
                    </div>
                </header>
                <main id="main" style="padding-top:0px" class="svelte-1tjcd38">
                    <div class="flex h-full w-full items-center justify-center"><svg role="status" class="inline -mt-px animate-spin dark:text-gray-600 w-8 h-8 text-gray-300 fill-purple-600" viewBox="0 0 100 101" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M100 50.5908C100 78.2051 77.6142 100.591 50 100.591C22.3858 100.591 0 78.2051 0 50.5908C0 22.9766 22.3858 0.59082 50 0.59082C77.6142 0.59082 100 22.9766 100 50.5908ZM9.08144 50.5908C9.08144 73.1895 27.4013 91.5094 50 91.5094C72.5987 91.5094 90.9186 73.1895 90.9186 50.5908C90.9186 27.9921 72.5987 9.67226 50 9.67226C27.4013 9.67226 9.08144 27.9921 9.08144 50.5908Z" fill="currentColor"></path><path d="M93.9676 39.0409C96.393 38.4038 97.8624 35.9116 97.0079 33.5539C95.2932 28.8227 92.871 24.3692 89.8167 20.348C85.8452 15.1192 80.8826 10.7238 75.2124 7.41289C69.5422 4.10194 63.2754 1.94025 56.7698 1.05124C51.7666 0.367541 46.6976 0.446843 41.7345 1.27873C39.2613 1.69328 37.813 4.19778 38.4501 6.62326C39.0873 9.04874 41.5694 10.4717 44.0505 10.1071C47.8511 9.54855 51.7191 9.52689 55.5402 10.0491C60.8642 10.7766 65.9928 12.5457 70.6331 15.2552C75.2735 17.9648 79.3347 21.5619 82.5849 25.841C84.9175 28.9121 86.7997 32.2913 88.1811 35.8758C89.083 38.2158 91.5421 39.6781 93.9676 39.0409Z" fill="currentFill"></path></svg>                        </div>
                </main>
            </div>
            <div class="article h-auto w-full svelte-1tjcd38">
                <div id="description" class="svelte-s9hg3b">
                    <div class="article-section svelte-s9hg3b" data-click="article-intro" data-svelte-h="svelte-1ts29ty">
                        <h1 class="svelte-s9hg3b">إيه هو الترانسفورمر؟</h1>
                        <p class="svelte-s9hg3b">الترانسفورمر هو عمارة الشبكة العصبية اللي غيرت طريقة تفكيرنا في الذكاء الاصطناعي من الأساس. ظهر لأول مرة في البحث الشهير
                            <a href="https://dl.acm.org/doi/10.5555/3295222.3295349" title="ACM Digital Library" target="_blank" class="svelte-s9hg3b">&quot;الانتباه هو كل حاجة&quot;</a> سنة 2017 ومبقاش حد بيتكلم عن موديلات التعلم العميق من غيره. هو اللي
                            بيشغل موديلات توليد النصوص زي
                            <strong>GPT</strong> بتاعة OpenAI و <strong>Llama</strong> بتاعة Meta و
                            <strong>Gemini</strong> بتاعة Google. مش بس كده، الترانسفورمر بيستخدم في
                            <a href="https://huggingface.co/learn/audio-course/en/chapter3/introduction" title="Hugging Face" target="_blank" class="svelte-s9hg3b">توليد الصوت</a>,
                            <a href="https://huggingface.co/learn/computer-vision-course/unit3/vision-transformers/vision-transformers-for-image-classification" title="Hugging Face" target="_blank" class="svelte-s9hg3b">التعرف على الصور</a>,
                            <a href="https://elifesciences.org/articles/82819" title="eLife" class="svelte-s9hg3b">التنبؤ بتركيب البروتينات</a>, وحتى في
                            <a href="https://www.deeplearning.ai/the-batch/reinforcement-learning-plus-transformers-equals-efficiency/" title="Deep Learning AI" target="_blank" class="svelte-s9hg3b">لعب الألعاب</a>, وده بيبين إنه تقنية متعددة الاستخدامات
                            جامدة.
                        </p>
                        <p class="svelte-s9hg3b">في الأساس، موديلات توليد النصوص بتاعة الترانسفورمر بتشتغل على مبدأ <strong>التنبؤ بالتوكن الجاي</strong>: يعني يبقى عندك نص مدخل من المستخدم، إيه
                            <em>أحتمل توكن (كلمة أو جزء من كلمة) جاي</em> هيظهر بعد المدخل ده؟ الحكاية كلها وقوة الترانسفورميرز في إنهم بيستخدموا آلية الانتباه الذاتي، اللي بتخليهم يقدروا يشتغلوا على التسلسل كله ويلموا العلاقات الطويلة بين الكلمات أحسن
                            من البنيات التانية.</p>
                        <p class="svelte-s9hg3b">عيلة موديلات GPT-2 ده مثال كويس على ترانسفورميرز توليد النصوص. ترانسفورمر إكسبلينر بيشتغل بموديل
                            <a href="https://huggingface.co/openai-community/gpt2" title="Hugging Face" target="_blank" class="svelte-s9hg3b">GPT-2</a> (الصغير) اللي عنده 124 مليون باراميتر. مع إنه مش أحدث أو أقوى موديل ترانسفورمر، بس فيه نفس المكونات
                            والأفكار الأساسية اللي في الموديلات الحديثة، فده بيساعد في الفهم الأساسي.</p>
                    </div>
                    <div class="article-section svelte-s9hg3b" data-click="article-overview" data-svelte-h="svelte-1l0kza3">
                        <h1 class="svelte-s9hg3b">هندسة الترانسفورمر</h1>
                        <p class="svelte-s9hg3b">كل ترانسفورمر لتوليد النصوص فيه <strong>تلات حاجات أساسية</strong> دي:</p>
                        <ol class="svelte-s9hg3b">
                            <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">التضمين (Embedding)</strong>: النص المدخل بيتقسم لوحدات أصغر اسمها توكنز، ممكن تكون كلمات أو أجزاء كلمات. التوكنز دي بيتحولوا لأرقام اسمها تضمينات، وهنا بيتقبض على المعاني المشتركة
                                للكلمات.
                            </li>
                            <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">بلوك الترانسفورمر</strong> ده هو الحجر الأساسي في الموديل اللي بيعالج ويحول البيانات المدخلة. كل بلوك فيه:
                                <ul class=" svelte-s9hg3b">
                                    <li class="svelte-s9hg3b"><strong>آلية الانتباه</strong>, الجزء الأساسي في البلوك. ده اللي بيخلّي التوكنز تتكلم مع بعض، ويفهم السياق والعلاقات بين الكلمات.</li>
                                    <li class="svelte-s9hg3b"><strong>طبقة MLP (الشبكة العصبية متعددة الطبقات)</strong>, شبكة تغذية أمامية بتشتغل على كل توكن لوحده. الانتباه بيوجه المعلومات بين التوكنز، أما الـMLP فهو بيحسن تمثيل كل توكن.</li>
                                </ul>
                            </li>
                            <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">الاحتمالات النهائية</strong>: أخر خطين (الخطي والسوفتماكس) بيحولوا التضمينات المعالجة لاحتمالات، عشان الموديل يقدر يتنبأ بالتوكن الجاي في التسلسل.</li>
                        </ol>
                    </div>
                    <div class="article-section svelte-s9hg3b" id="embedding" data-click="article-embedding" data-svelte-h="svelte-184pfd5">
                        <h2 class="svelte-s9hg3b">التضمين</h2>
                        <p class="svelte-s9hg3b">تخيل إنك عايز تولد نص باستخدام موديل ترانسفورمر. هتضيف البداية زي دي:
                            <code class="svelte-s9hg3b">&quot;تخليك البيانات المرئية تقدر&quot;</code>. المدخل ده لازم يتحول لصيغة الموديل يفهمها ويعالجها. هنا بيجي دور التضمين: إنه يحول النص لتمثيل رقمي عشان الموديل يشتغل عليه. عشان نحول البداية لتضمين،
                            محتاجين 1) تقسيم النص (Tokenization)، 2) نجيب تضمينات التوكنز، 3) نضيف معلومات المكان، وأخيرًا 4) نجمع تضمينات التوكنز والمكان عشان نلاقي التضمين النهائي. تعالى نشوف كل خطوة إزاي بتتم.</p>
                        <div class="figure svelte-s9hg3b"><img src="/transExP/article_assets/embedding.png" width="65%" class="svelte-s9hg3b"></div>
                        <div class="figure-caption svelte-s9hg3b">الشكل <span class="attention">1</span>. طريقة التضمين، بتوضح إزاي البداية بتتحول لمتجه رقمي. العملية فيها
                            <span class="fig-numbering">(1)</span> تقسيم النص، (2) تضمين التوكنز، (3) تضمين المكان، و(4) التضمين النهائي.</div>
                        <div class="article-subsection svelte-s9hg3b">
                            <h3 class="svelte-s9hg3b">الخطوة 1: تقسيم النص (Tokenization)</h3>
                            <p class="svelte-s9hg3b">تقسيم النص هو عملية تكسير النص المدخل لقطع صغيرة اسمها توكنز. التوكنز دول ممكن يكونوا كلمة أو جزء كلمة. الكلمات <code class="svelte-s9hg3b">&quot;البيانات&quot;</code> و <code class="svelte-s9hg3b">&quot;المرئية&quot;</code>                                بتوعهم توكنز فريدة، أما كلمة
                                <code class="svelte-s9hg3b">&quot;تخليك&quot;</code> هتتقسم لتوكنين. كل التوكنز اللي ممكن تظهر بتتحدد قبل تدريب الموديل: قاموس GPT-2 فيه <code class="svelte-s9hg3b">50,257</code> توكن فريد. دلوقتي بعد ما قسمنا النص لتوكنز
                                وأرقام فريدة، نقدر ناخد تمثيلهم الرقمي من التضمينات.</p>
                        </div>
                        <div class="article-subsection svelte-s9hg3b" id="article-token-embedding">
                            <h3 class="svelte-s9hg3b">الخطوة 2: تضمين التوكنز</h3>
                            <p class="svelte-s9hg3b">GPT-2 (الصغير) بيمثل كل توكن في القاموس كمتجه بعد 768؛ البعد بتاع المتجه ده بيختلف حسب الموديل. تضمينات التوكنز دي بتتخزن في مصفوفة شكلها <code class="svelte-s9hg3b">(50,257, 768)</code>, فيها حوالي 39 مليون باراميتر! المصفوفة
                                الكبيرة دي بتخلي الموديل يدي معنى دلالي لكل توكن، يعني التوكنز اللي استخدامهم أو معناهم في اللغة متقاربين، هيبقوا قريبين من بعض في المساحة دي، أما التوكنز المختلفة تبقى بعيدة.</p>
                        </div>
                        <div class="article-subsection svelte-s9hg3b" id="article-positional-embedding">
                            <h3 class="svelte-s9hg3b">الخطوة 3: تضمين المكان</h3>
                            <p class="svelte-s9hg3b">طبقة التضمين كمان بتخزن معلومات عن مكان كل توكن في البداية. موديلات مختلفة بتستخدم طرق مختلفة لتضمين المكان. GPT-2 بيدرب مصفوفة تضمين المكان بتاعته من الأول، ويدمجها في عملية التدريب مباشرة.</p>
                        </div>
                        <div class="article-subsection svelte-s9hg3b">
                            <h3 class="svelte-s9hg3b">الخطوة 4: التضمين النهائي</h3>
                            <p class="svelte-s9hg3b">أخيرًا، بنجمع تضمين التوكنز وتضمين المكان عشان ناخد التمثيل النهائي. التمثيل المجمع ده بيلم المعنى الدلالي للتوكنز ومكانهم في التسلسل المدخل.</p>
                        </div>
                    </div>
                    <div class="article-section svelte-s9hg3b" data-click="article-transformer-block" data-svelte-h="svelte-gdnki1">
                        <h2 class="svelte-s9hg3b">بلوك الترانسفورمر</h2>
                        <p class="svelte-s9hg3b">جوهر معالجة الترانسفورمر بيبقى في البلوك، واللي بيحتوي على الانتباه الذاتي متعدد الرؤوس وطبقة الشبكة العصبية متعددة الطبقات. أغلب الموديلات بتكون من كذا بلوك متراصين فوق بعض. تمثيلات التوكنز بتتطور من الطبقة الأولى للأخيرة، عشان
                            الموديل يبني فهم معقد لكل توكن. الطريقة الطباقية دي بتوصل لتمثيلات عالية المستوى للمدخل. موديل GPT-2 (الصغير) اللي بنشوفه ده مكون من <code class="svelte-s9hg3b">12</code> بلوك زي كده.</p>
                    </div>
                    <div class="article-section svelte-s9hg3b" id="self-attention" data-click="article-attention">
                        <h3 class="svelte-s9hg3b" data-svelte-h="svelte-1ndcxbz">الانتباه الذاتي متعدد الرؤوس</h3>
                        <p class="svelte-s9hg3b" data-svelte-h="svelte-1prun41">آلية الانتباه الذاتي بتخلي الموديل يفهم العلاقات بين التوكنز في التسلسل، عشان تمثيل كل توكن يتأثر بالباقيين. الانتباه متعدد الرؤوس بيخلي الموديل يفكر في العلاقات دي من وجهات نظر مختلفة؛ مثلاً راس ممكن يفهم العلاقات النحوية القصيرة
                            وراس تاني ممكن يتابع السياق الدلالي الواسع. في الجزء الجاي هنعدّي على طريقة حساب الانتباه الذاتي متعدد الرؤوس خطوة خطوة.</p>
                        <div class="article-subsection-l2 svelte-s9hg3b">
                            <h4 class="svelte-s9hg3b" data-svelte-h="svelte-1lftxsb">الخطوة 1: مصفوفات الاستعلام، المفتاح، والقيمة</h4>
                            <div class="figure pt-10 svelte-s9hg3b"><img src="/transExP/article_assets/QKV.png" width="80%" class="svelte-s9hg3b">
                                <div class="text-xs svelte-s9hg3b">
                                    <!-- HTML_TAG_START --><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mi>K</mi><msub><mi>V</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><munderover><mo>∑</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mn>768</mn></munderover><msub><mtext>التضمين</mtext><mrow><mi>i</mi><mo separator="true">,</mo><mi>d</mi></mrow></msub><mo>⋅</mo><msub><mtext>الأوزان</mtext><mrow><mi>d</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mtext>الانحياز</mtext><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">
		QKV_{ij} = ( \sum_{d=1}^{768} \text{التضمين}_{i,d} \cdot \text{الأوزان}_{d,j}) + \text{الانحياز}_j
		</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">Q</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span>
                                    <span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span>
                                    <span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span>
                                    </span>
                                    </span>
                                    </span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span>
                                    </span>
                                    </span>
                                    </span>
                                    </span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1032em;vertical-align:-1.3021em;"></span>
                                    <span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span>
                                    <span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span>
                                    </span>
                                    </span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span>
                                    </span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">768</span></span>
                                    </span>
                                    </span>
                                    </span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span>
                                    </span>
                                    </span>
                                    </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord text"><span class="mord">التضمين</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span>
                                    <span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">d</span></span>
                                    </span>
                                    </span>
                                    </span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span>
                                    </span>
                                    </span>
                                    </span>
                                    </span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span>
                                    <span class="mord"><span class="mord text"><span class="mord">الأوزان</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span>
                                    <span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span>
                                    </span>
                                    </span>
                                    </span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span>
                                    </span>
                                    </span>
                                    </span>
                                    </span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span>
                                    <span class="base"><span class="strut" style="height:0.5978em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord text"><span class="mord">الانحياز</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span>
                                    <span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span>
                                    </span>
                                    </span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span>
                                    </span>
                                    </span>
                                    </span>
                                    </span>
                                    </span>
                                    </span>
                                    </span>
                                    </span>
                                    <!-- HTML_TAG_END -->
                                </div>
                            </div>
                            <div class="figure-caption svelte-s9hg3b" data-svelte-h="svelte-piw2p2">الشكل <span class="attention">2</span>. طريقة حساب مصفوفات الاستعلام، المفتاح، والقيمة من التضمين الأصلي.</div>
                            <p class="svelte-s9hg3b" data-svelte-h="svelte-1d9yjz7">كل تضمين للتوكن بيتحول لثلاثة متجهات:
                                <span class="q-color svelte-s9hg3b">الاستعلام (Q)</span>,
                                <span class="k-color svelte-s9hg3b">المفتاح (K)</span>, و
                                <span class="v-color svelte-s9hg3b">القيمة (V)</span>. المتجهات دي بتطلع بضرب مصفوفة التضمين في مصفوفات الأوزان المتعلمة للـ
                                <span class="q-color svelte-s9hg3b">Q</span>,
                                <span class="k-color svelte-s9hg3b">K</span>, و
                                <span class="v-color svelte-s9hg3b">V</span>. في تشبيه محرك البحث عشان نفهم الحاجات دي:</p>
                            <ul class="svelte-s9hg3b" data-svelte-h="svelte-1qrm0nu">
                                <li class="svelte-s9hg3b"><strong class="q-color font-medium svelte-s9hg3b">الاستعلام (Q)</strong> هو النص اللي بتكتبه في مربع البحث. ده التوكن اللي عايز
                                    <em>&quot;تلاقي معلومات أكتر عنه&quot;</em>.</li>
                                <li class="svelte-s9hg3b"><strong class="k-color font-medium svelte-s9hg3b">المفتاح (K)</strong> هو عنوان كل صفحة ويب في نتائج البحث. بيتمثل في التوكنز اللي الاستعلام ممكن يهتم بيهم.</li>
                                <li class="svelte-s9hg3b"><strong class="v-color font-medium svelte-s9hg3b">القيمة (V)</strong> هو المحتوى الحقيقي لصفحات الويب. بعد ما نوّفق مصطلح البحث (الاستعلام) مع النتائج المناسبة (المفتاح)، عايزين ناخد المحتوى (القيمة) للصفحات الأكثر علاقة.</li>
                            </ul>
                            <p class="svelte-s9hg3b" data-svelte-h="svelte-1lwtlkg">باستخدام قيم QKV دي، الموديل يقدر يحسب درجات الانتباه، واللي بتحدد قد إيه كل توكن يستحق التركيز لما الموديل يتنبأ.</p>
                        </div>
                        <div class="article-subsection-l2 svelte-s9hg3b" data-svelte-h="svelte-x6cb9a">
                            <h4 class="svelte-s9hg3b">الخطوة 2: تقسيم الرؤوس المتعددة</h4>
                            <p class="svelte-s9hg3b">متجهات <span class="q-color svelte-s9hg3b">الاستعلام</span>, <span class="k-color svelte-s9hg3b">المفتاح</span>, و
                                <span class="v-color svelte-s9hg3b">القيمة</span> بتتقسّم لرؤوس كتيرة - في حالة GPT-2 (الصغير)، لـ
                                <code class="svelte-s9hg3b">12</code> راس. كل راس بيعالج جزء من التضمينات على حده، ويفهم علاقات نحوية ودلالية مختلفة. التصميم ده بيخلي التعليم الموازي للخصائص اللغوية المختلفة يشتغل بسرعة، وبيقوي قدرة التمثيل عند الموديل.</p>
                        </div>
                        <div class="article-subsection-l2 svelte-s9hg3b" data-svelte-h="svelte-113xffx">
                            <h4 class="svelte-s9hg3b">الخطوة 3: الانتباه الذاتي المقنّع</h4>
                            <p class="svelte-s9hg3b">في كل راس، بنعمل حسابات الانتباه الذاتي المقنّع. الآلية دي بتخلي الموديل يتنبأ بتسلسل عن طريق التركيز على الأجزاء المهمة من المدخل وفي نفس الوقت مش بيقدر يطلع على التوكنز الجاية.</p>
                            <div class="figure svelte-s9hg3b"><img src="/transExP/article_assets/attention.png" width="80%" align="middle" class="svelte-s9hg3b"></div>
                            <div class="figure-caption svelte-s9hg3b">الشكل <span class="attention">3</span>. استخدام مصفوفات الاستعلام، المفتاح، والقيمة لحساب الانتباه الذاتي المقنّع.</div>
                            <ul class="svelte-s9hg3b">
                                <li class="svelte-s9hg3b"><strong>الضرب النقطي</strong>: الضرب النقطي لمصفوفتي
                                    <span class="q-color svelte-s9hg3b">الاستعلام</span> و <span class="k-color svelte-s9hg3b">المفتاح</span> بيحدد
                                    <strong>درجة الانتباه</strong>, وبينتج مصفوفة مربعة بتعكس العلاقة بين كل التوكنز المدخلة.</li>
                                <li class="svelte-s9hg3b"><strong>القياس · القناع</strong>: درجات الانتباه بتتقيّم وقناع بيتطبق على المثلث العلوي لمصفوفة الانتباه عشان الموديل ميقدرش يوصل للتوكنز الجاية، والقيم دي بتتغير لسالب مالا نهاية. الموديل محتاج يتعلم يتنبأ بالتوكن الجاي
                                    من غير ما يـ&quot;يفتش&quot; في الجاية.</li>
                                <li class="svelte-s9hg3b"><strong>السوفتماكس · الإسقاط</strong>: بعد القناع والقياس، درجات الانتباه بتتحول لاحتمالات عن طريق السوفتماكس، وبعد كده ممكن تتعدل بالإسقاط. كل صف في المصفوفة مجموعه واحد وبيشير لأهمية كل التوكنز اللي على شماله.</li>
                            </ul>
                        </div>
                        <div class="article-subsection-l2 svelte-s9hg3b" data-svelte-h="svelte-1b6jrzl">
                            <h4 class="svelte-s9hg3b">الخطوة 4: الإخراج والدمج</h4>
                            <p class="svelte-s9hg3b">الموديل بيستخدم درجات الانتباه الذاتي المقنّع ويضربهم في مصفوفة <span class="v-color svelte-s9hg3b">القيمة</span> عشان ياخد
                                <span class="purple-color svelte-s9hg3b">الإخراج النهائي</span> لآلية الانتباه الذاتي. GPT-2 عنده <code class="svelte-s9hg3b">12</code> راس انتباه ذاتي، كل راس بيفهم علاقات مختلفة بين التوكنز. مخرجات الرؤوس دي بتتدمج وتمر
                                على إسقاط خطي.</p>
                        </div>
                    </div>
                    <div class="article-section svelte-s9hg3b" id="article-activation" data-click="article-mlp" data-svelte-h="svelte-15tpu87">
                        <h3 class="svelte-s9hg3b">MLP: الشبكة العصبية متعددة الطبقات</h3>
                        <div class="figure svelte-s9hg3b"><img src="/transExP/article_assets/mlp.png" width="70%" align="middle" class="svelte-s9hg3b"></div>
                        <div class="figure-caption svelte-s9hg3b">الشكل <span class="attention">4</span>. استخدام طبقة MLP عشان تمثيلات الانتباه الذاتي تتوقع في أبعاد أعلى عشان تقدر تمثل أكتر.</div>
                        <p class="svelte-s9hg3b">بعد ما رؤوس الانتباه الذاتي الكتيرة تلم العلاقات المختلفة بين التوكنز المدخلة، المخرجات المدمجة بتعدي على طبقة MLP عشان تقدر تمثل أكتر. بلوك MLP مكون من تحويلين خطيين مع دالة تفعيل <a href="https://en.wikipedia.org/wiki/Rectified_linear_unit#Gaussian-error_linear_unit_(GELU)"
                                class="svelte-s9hg3b">GELU</a> بينهم.</p>
                        <p class="svelte-s9hg3b">التحويل الخطي الأول بيفتح بعد المدخل أربع أضعاف من <code class="svelte-s9hg3b">768</code> لـ
                            <code class="svelte-s9hg3b">3072</code>. الخطوة التوسعية دي بتخلي الموديل يوقع تمثيلات التوكنز في مساحة أعلى بعد، عشان يقدر يفهم أنماط أغنى وأعقد ممكن متتبانش في البعد الأصلي.</p>
                        <p class="svelte-s9hg3b">التحويل الخطي التاني بيقلل البعد تاني للحجم الأصلي اللي هو <code class="svelte-s9hg3b">768</code>. خطوة الضغط دي بترجع التمثيلات لحجم متحكم فيه وفي نفس الوقت بتحتفظ بالتغيرات غير الخطية المفيدة اللي اتعملت في خطوة التوسع.</p>
                        <p class="svelte-s9hg3b">على عكس آلية الانتباه الذاتي، اللي بتدمج معلومات بين التوكنز، الـMLP بيفرز كل توكن على حده وببساطة بيمثل كل توكن من مساحة لمساحة، وبيزيد السعة الإجمالية للموديل.</p>
                    </div>
                    <div class="article-section svelte-s9hg3b" id="article-prob" data-click="article-prob" data-svelte-h="svelte-rntvaj">
                        <h2 class="svelte-s9hg3b">الاحتمالات النهائية</h2>
                        <p class="svelte-s9hg3b">بعد ما المدخل يتعالج من كل بلوكات الترانسفورمر، الإخراج بيعدي على الطبقة الخطية الأخيرة عشان يتجهز لتنبؤ التوكن. الطبقة دي بتوقع التمثيلات النهائية في مساحة بعد <code class="svelte-s9hg3b">50,257</code> ، وكل توكن في القاموس ليه
                            قيمة مقابلة اسمها
                            <code class="svelte-s9hg3b">logit</code>. أي توكن ممكن يكون الكلمة الجاية، فالعمليه دي بتخلينا ببساطة نرتب التوكنز دي حسب احتمال إنهم يبقوا الكلمة الجاية. بعد كده بنطبق دالة السوفتماكس عشان نحول الـlogits لاحتمالات مجموعها
                            واحد. ده هيخلينا نقدر نختار التوكن الجاي على أساس احتماله.</p>
                        <div class="figure py-5 svelte-s9hg3b"><img src="/transExP/article_assets/softmax.png" width="70%" class="svelte-s9hg3b"></div>
                        <div class="figure-caption svelte-s9hg3b">الشكل <span class="attention">5</span>. كل توكن في القاموس بياخد احتمالية على أساس لوجيتس الموديل. الاحتماليات دي بتحدد قد إيه كل توكن محتمل إنه يكون الكلمة الجاية في التسلسل.</div>
                        <p id="article-temperature" data-click="article-temperature" class="svelte-s9hg3b">الخطوة الأخيرة هي توليد التوكن الجاي عن طريق اختيار من التوزيع ده. الـ<code class="svelte-s9hg3b">temperature</code> (درجة الحرارة) هيلعب دور مهم جدًا في العملية دي. رياضياً، هي عملية بسيطة أوي: لوجيتس المخرجات بتتقسم على
                            <code class="svelte-s9hg3b">temperature</code>:</p>
                        <ul class="svelte-s9hg3b">
                            <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature = 1</code>: قسمة الـlogits على واحد مش بتأثر على مخرجات السوفتماكس.</li>
                            <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature &lt; 1</code>: درجة الحرارة المنخفضة بتخلي الموديل أكتر ثقة وأكتر حتمية عن طريق شحذ توزيع الاحتمالات، وده بيوصل لنتائج أكتر توقع.</li>
                            <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature &gt; 1</code>: درجة الحرارة العالية بتخلق توزيع احتمالي أنعم، وبتخلي النص اللي بيتولد أكتر عشوائية - اللي ناس بتقول عليه
                                <em>&quot;الإبداع&quot;</em> بتاع الموديل.</li>
                        </ul>
                        <p id="article-sampling" data-click="article-sampling" class="svelte-s9hg3b">كمان، عملية الاختيار ممكن تتحسن باستخدام باراميترات <code class="svelte-s9hg3b">top-k</code> و
                            <code class="svelte-s9hg3b">top-p</code>:</p>
                        <ul class="svelte-s9hg3b">
                            <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">top-k sampling</code>: بيحدد التوكنز المرشحة لأعلى k توكنز مع أعلى احتمالات، وبيشيل الخيارات الأقل احتمالاً.</li>
                            <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">top-p sampling</code>: بياخد أصغر مجموعة توكنز مجموع احتمالاتهم يتعدى عتبة p، بيضمن إن بس التوكنز الأكتر احتمالاً هيساهموا وفي نفس الوقت بيسمح بتنوع.</li>
                        </ul>
                        <p class="svelte-s9hg3b">عن طريق ضبط <code class="svelte-s9hg3b">temperature</code>, <code class="svelte-s9hg3b">top-k</code>, و <code class="svelte-s9hg3b">top-p</code>, تقدر توازن بين النتائج الحتمية والمتنوعة، وتعدّل سلوك الموديل عشان يناسب احتياجاتك.</p>
                    </div>
                    <div class="article-section svelte-s9hg3b" data-click="article-advanced-features" data-svelte-h="svelte-1auuydd">
                        <h2 class="svelte-s9hg3b">مميزات هندسية إضافية</h2>
                        <p class="svelte-s9hg3b">في مميزات هندسية إضافية كتيرة بتقوي أداء موديلات الترانسفورمر. مع إنهم مهمين لأداء الموديل ككل، بس مش قد أهمية فهم الأفكار الأساسية للهندسة. التطبيع الطبقي، الإسقاط، والوصلات المتبقية حاجات مهمة جدًا في موديلات الترانسفورمر، خصوصًا
                            في مرحلة التدريب. التطبيع الطبقي بيثبت التدريب ويساعد الموديل يوصل أسرع. الإسقاط بيقاوم التكيّف الزائد عن طريق تعطيل عشوائي للخلايا العصبية. الوصلات المتبقية بتخلّي الانحدارات تعدي مباشر في الشبكة وتساعد في مشكلة انحدار التلاشي.</p>
                        <div class="article-subsection svelte-s9hg3b" id="article-ln">
                            <h3 class="svelte-s9hg3b">التطبيع الطبقي</h3>
                            <p class="svelte-s9hg3b">التطبيع الطبقي بيقوي عملية التدريب ويحسن الوصول. بيشتغل عن طريق توحيد المدخلات عبر الخصائص، وبيضمن إن المتوسط والتباين في التنشيطات يكونوا متناسقين. التوحيد ده بيقلل المشاكل المتعلقة بتحول التغاير الداخلي، وبيخلي الموديل يتعلم
                                أكتر بفعالية ويقلل الحساسية للأوزان الأولية. التطبيع الطبقي بيتطبق مرتين في كل بلوك ترانسفورمر، مرة قبل آلية الانتباه الذاتي ومرة قبل طبقة MLP.</p>
                        </div>
                        <div class="article-subsection svelte-s9hg3b" id="article-dropout">
                            <h3 class="svelte-s9hg3b">الإسقاط</h3>
                            <p class="svelte-s9hg3b">الإسقاط هو تقنية تنظيم بتستعمل عشان تمنع التكيّف الزائد في الشبكات العصبية عن طريق تعطيل جزء عشوائي من أوزان الموديل خلال التدريب. ده بيشجع الموديل يتعلم خصائص أقوى ويقلل الاعتماد على خلايا عصبية معينة، ويساعد الشبكة تعمم أحسن
                                على بيانات جديدة مش متدربة عليها. خلال استدلال الموديل، الإسقاط بيتعطل. ده معناه إننا بنستخدم مجموعة من الشبكات الفرعية المتدربة، واللي بيوصل لأداء أحسن للموديل.</p>
                        </div>
                        <div class="article-subsection svelte-s9hg3b" id="article-residual">
                            <h3 class="svelte-s9hg3b">الوصلات المتبقية</h3>
                            <p class="svelte-s9hg3b">الوصلات المتبقية ظهرت لأول مرة في موديل ResNet سنة 2015. الإبداع الهندسي ده غيّر التعلم العميق عن طريق تمكين تدريب شبكات عصبية عميقة جدًا. في الأساس، الوصلات المتبقية هي اختصارات بتعدي على واحدة أو كذا طبقة، وبتضيف مدخل الطبقة
                                لمخرجها. ده بيقلل مشكلة انحدار التلاشي، وبيخلي تدريب الشبكات العميقة مع كذا بلوك ترانسفورمر متراصين على بعض أسهل. في GPT-2، الوصلات المتبقية بتستخدم مرتين في كل بلوك ترانسفورمر: مرة قبل الـMLP ومرة بعدها، عشان تضمن إن الانحدارات
                                تعدي بسهولة أكتر، والطبقات الأولية تستلم تحديثات كافية خلال الانتشار الخلفي.</p>
                        </div>
                    </div>
                    <div class="article-section svelte-s9hg3b" data-click="article-interactive-features" data-svelte-h="svelte-mnf1ro">
                        <h1 class="svelte-s9hg3b">مميزات تفاعلية</h1>
                        <p class="svelte-s9hg3b">ترانسفورمر إكسبلينر معمول عشان يكون تفاعلي ويخليك تستكشف طريقة عمل الترانسفورمر من جوا. دي بعض المميزات التفاعلية اللي تقدر تلعب بيها:</p>
                        <ul class="svelte-s9hg3b">
                            <li class="svelte-s9hg3b"><strong>ادخل تسلسل النص بتاعك</strong> عشان تشوف إزاي الموديل بيعالجه ويتنبأ بالكلمة الجاية. استكشف أوزان الانتباه، العمليات الوسيطة، وشوف إزاي الاحتمالات النهائية بتتحسب.</li>
                            <li class="svelte-s9hg3b"><strong>استخدم سلايدر درجة الحرارة</strong> عشان تتحكم في عشوائية تنبؤات الموديل. استكشف إزاي تقدر تخلي مخرجات الموديل أكتر حتمية أو أكتر إبداع عن طريق تغيير قيمة درجة الحرارة.</li>
                            <li class="svelte-s9hg3b"><strong>اختار طرق أخذ العينات top-k و top-p</strong> عشان تعدّل سلوك الأخذ خلال الاستدلال. جرب قيم مختلفة وشوف إزاي توزيع الاحتمالات بيتغير ويأثر على تنبؤات الموديل.</li>
                            <li class="svelte-s9hg3b"><strong>تفاعل مع خرائط الانتباه</strong> عشان تشوف إزاي الموديل بيتركز على توكنز مختلفة في تسلسل المدخل. حُط على التوكنز عشان توضح أوزان انتباهم واستكشف إزاي الموديل بيقبض على السياق والعلاقات بين الكلمات.</li>
                        </ul>
                    </div>
                    <div class="article-section svelte-s9hg3b" data-click="article-video" data-svelte-h="svelte-u7199m">
                        <h2 class="svelte-s9hg3b">فيديو تعليمي</h2>
                        <div class="video-container svelte-s9hg3b"><iframe src="https://www.youtube.com/embed/ECR4oAwocjs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen class="svelte-s9hg3b"></iframe></div>
                    </div>
                    <div class="article-section svelte-s9hg3b" data-click="article-implementation" data-svelte-h="svelte-qc2l02">
                        <h2 class="svelte-s9hg3b">إزاي تم تطبيق ترانسفورمر إكسبلينر؟</h2>
                        <p class="svelte-s9hg3b">ترانسفورمر إكسبلينر فيه موديل GPT-2 (الصغير) مباشر بيشتغل في البراوزر. الموديل ده مأخوذ من تنفيذ PyTorch للـGPT بتاع مشروع
                            <a href="https://github.com/karpathy/nanoGPT" title="Github" target="_blank" class="svelte-s9hg3b">nanoGPT</a> لـAndrej Karpathy واتحول لـ
                            <a href="https://onnxruntime.ai/" title="ONNX" target="_blank" class="svelte-s9hg3b">ONNX Runtime</a> عشان يشتغل بسلاسة في البراوزر. الواجهة معمولة باستخدام JavaScript، مع
                            <a href="https://kit.svelte.dev/" title="Svelte" target="_blank" class="svelte-s9hg3b">Svelte</a> كإطار واجهة أمامية و
                            <a href="https://d3js.org/" title="D3" target="_blank" class="svelte-s9hg3b">D3.js</a> لعمل التصورات الديناميكية. القيم الرقمية بتتحدث مباشرة على أساس مدخلات المستخدم.</p>
                    </div>
                    <div class="article-section svelte-s9hg3b" data-click="article-credit" data-svelte-h="svelte-eprtso">
                        <h2 class="svelte-s9hg3b">مين اللي طور ترانسفورمر إكسبلينر؟</h2>
                        <p class="svelte-s9hg3b">ترانسفورمر إكسبلينر اتعمل بواسطة

                            <a href="https://aereeeee.github.io/" target="_blank" class="svelte-s9hg3b">Aeree Cho</a>,
                            <a href="https://www.linkedin.com/in/chaeyeonggracekim/" target="_blank" class="svelte-s9hg3b">Grace C. Kim</a>,
                            <a href="https://alexkarpekov.com/" target="_blank" class="svelte-s9hg3b">Alexander Karpekov</a>,
                            <a href="https://alechelbling.com/" target="_blank" class="svelte-s9hg3b">Alec Helbling</a>,
                            <a href="https://zijie.wang/" target="_blank" class="svelte-s9hg3b">Jay Wang</a>,
                            <a href="https://seongmin.xyz/" target="_blank" class="svelte-s9hg3b">Seongmin Lee</a>,
                            <a href="https://bhoov.com/" target="_blank" class="svelte-s9hg3b">Benjamin Hoover</a>, و
                            <a href="https://poloclub.github.io/polochau/" target="_blank" class="svelte-s9hg3b">Polo Chau</a> في معهد جورجيا للتكنولوجيا.</p>
                    </div>
                </div>
            </div>
        </div>


















        <script>
            // SvelteKit initialization
            {
                __sveltekit_158dv = {
                    base: new URL(".", location).pathname.slice(0, -1),
                    assets: "/transformer-explainer"
                };

                const element = document.currentScript.parentElement;

                Promise.all([
                    import ("/transExP/_app/immutable/entry/start.CeaJo41a.js"),
                    import ("/transExP/_app/immutable/entry/app.Bp1a5M9n.js")
                ]).then(([kit, app]) => {
                    kit.start(app, element, {
                        node_ids: [0, 2],
                        data: [null, null],
                        form: null,
                        error: null
                    });

                    // ✅ CRITICAL: Initialize RTL AFTER Svelte app is loaded
                    setTimeout(initRTLController, 100);
                });
            }

            // RTL/LTR direction controller - DEFER INITIALIZATION
            function initRTLController() {
                console.log("Initializing RTL controller...");

                function setLTR(el) {
                    if (!el || el.nodeType !== 1) return;
                    el.style.setProperty('direction', 'ltr', 'important');
                    el.style.setProperty('text-align', 'left', 'important');
                }

                function setRTL(el) {
                    if (!el || el.nodeType !== 1) return;
                    el.style.setProperty('direction', 'rtl', 'important');
                    el.style.setProperty('text-align', 'right', 'important');
                }

                function setNeutral(el) {
                    if (!el || el.nodeType !== 1) return;
                    el.style.setProperty('direction', 'ltr', 'important');
                    el.style.setProperty('text-align', 'center', 'important');
                }

                function applyRTLToElement(el) {
                    if (!el || el.nodeType !== 1) return;

                    // Skip if already processed
                    if (el.dataset.rtlProcessed === 'true') return;

                    // Text cards and related components are RTL
                    if (el.matches('.text-card, .text-card *, .card-header, .card-body, .carousel-content, .carousel-slide, .textbook-content')) {
                        // But exclude navigation buttons and icons
                        if (!el.matches('.nav-arrow-circle, .nav-arrow-circle *, svg, .nav-section, .navigation-footer, .close-btn, button[class*="close"], .page-counter')) {
                            setRTL(el);
                        }
                    }
                    // Headings and paragraphs are always RTL
                    else if (el.matches('h1, h2, h3, h4, h5, h6, p, span, strong, em, blockquote, li, ul, ol')) {
                        setRTL(el);
                    }
                    // Other containers that should be RTL
                    else if (el.matches('.floating-container, .floating-container *, .numbered-list, .numbered-item, .item-content')) {
                        setRTL(el);
                    }
                    // Navigation elements should stay LTR/neutral
                    else if (el.matches('.nav-arrow-circle, .nav-arrow-circle *, .nav-section, .navigation-footer, .page-counter')) {
                        setNeutral(el);
                    }
                    // Button elements (close buttons, etc.) should stay LTR
                    else if (el.matches('.close-btn, button[class*="close"], button')) {
                        setLTR(el);
                    }
                    // Main elements should be LTR
                    else if (el.matches('main, main *')) {
                        setLTR(el);
                    }

                    // Mark as processed
                    el.dataset.rtlProcessed = 'true';
                }

                function applyRTLStyles(rootElement = document.body) {
                    if (!rootElement) return;

                    // Apply to the root element itself
                    applyRTLToElement(rootElement);

                    // Apply to all children
                    const allElements = rootElement.querySelectorAll('*');
                    allElements.forEach(el => applyRTLToElement(el));
                }

                function forceRTLOnTextCard() {
                    // Look for the specific text card with the svelte-dabew1 class
                    const textCards = document.querySelectorAll('.text-card.svelte-dabew1, .floating-container.svelte-dabew1');

                    textCards.forEach(card => {
                        // console.log("Found text card:", card);

                        // Set RTL on the card itself
                        setRTL(card);

                        // Get all descendants except navigation/button elements
                        const allDescendants = card.querySelectorAll('*');
                        allDescendants.forEach(descendant => {
                            // Skip navigation and button elements
                            if (descendant.matches('.nav-arrow-circle, .nav-arrow-circle *, .nav-section, .navigation-footer, .close-btn, button[class*="close"], svg, .page-counter, button')) {
                                setNeutral(descendant);
                                // Ensure SVG icons are not affected by RTL
                                if (descendant.matches('svg')) {
                                    descendant.style.transform = 'none';
                                    descendant.style.transformBox = 'fill-box';
                                }
                            } else {
                                // Force RTL on everything else
                                setRTL(descendant);
                            }
                            descendant.dataset.rtlProcessed = 'true';
                        });

                        // Also force RTL on specific text elements that might resist
                        const forceRtlElements = card.querySelectorAll('h1, h2, h3, h4, h5, h6, p, span, strong, em, blockquote, li, ul, ol, .textbook-content, .carousel-content, .carousel-slide, .card-header, .card-body, .numbered-list, .numbered-item, .item-content, .question');
                        forceRtlElements.forEach(el => {
                            el.style.setProperty('direction', 'rtl', 'important');
                            el.style.setProperty('text-align', 'right', 'important');
                            el.style.setProperty('unicode-bidi', 'embed', 'important');
                        });

                        // Ensure navigation buttons stay LTR/neutral
                        const navigationElements = card.querySelectorAll('.nav-arrow-circle, .nav-arrow-circle *, .nav-section, .navigation-footer, .page-counter, button');
                        navigationElements.forEach(el => {
                            el.style.setProperty('direction', 'ltr', 'important');
                            el.style.setProperty('text-align', 'center', 'important');
                            el.style.setProperty('unicode-bidi', 'normal', 'important');
                        });

                        // Special handling for SVG arrows
                        const svgArrows = card.querySelectorAll('svg');
                        svgArrows.forEach(svg => {
                            svg.style.direction = 'ltr';
                            svg.style.transform = 'none';
                            svg.style.transformBox = 'fill-box';
                            svg.style.unicodeBidi = 'normal';
                        });
                    });

                    // Also check for any Arabic text and force RTL
                    const elementsWithArabic = document.querySelectorAll('*');
                    elementsWithArabic.forEach(el => {
                        if (el.textContent && /[\u0600-\u06FF]/.test(el.textContent)) {
                            // Don't apply to navigation/button elements
                            if (!el.matches('.nav-arrow-circle, .nav-arrow-circle *, .nav-section, .navigation-footer, .close-btn, button[class*="close"], svg, .page-counter, button')) {
                                setRTL(el);
                                el.style.setProperty('unicode-bidi', 'embed', 'important');
                            }
                        }
                    });
                }

                // Special function to protect navigation elements
                function protectNavigationElements() {
                    // Find all navigation elements and ensure they stay LTR
                    const navElements = document.querySelectorAll('.navigation-footer, .nav-section, .nav-arrow-circle, .page-counter');
                    navElements.forEach(el => {
                        el.style.direction = 'ltr';
                        el.style.textAlign = 'center';
                        el.style.unicodeBidi = 'normal';

                        // Ensure all children also stay LTR
                        const children = el.querySelectorAll('*');
                        children.forEach(child => {
                            child.style.direction = 'ltr';
                            child.style.textAlign = 'center';
                            child.style.unicodeBidi = 'normal';
                        });
                    });

                    // Protect SVG icons
                    const svgIcons = document.querySelectorAll('svg');
                    svgIcons.forEach(svg => {
                        svg.style.direction = 'ltr';
                        svg.style.transform = 'none';
                        svg.style.transformBox = 'fill-box';
                    });

                    // Protect buttons
                    const buttons = document.querySelectorAll('button');
                    buttons.forEach(button => {
                        button.style.direction = 'ltr';
                        button.style.textAlign = 'center';
                    });
                }

                // Initial application with multiple attempts
                function initialRTLSetup() {
                    console.log("Performing initial RTL setup...");

                    // Try immediately
                    forceRTLOnTextCard();
                    protectNavigationElements();
                    applyRTLStyles();

                    // Try again after a short delay
                    setTimeout(() => {
                        forceRTLOnTextCard();
                        protectNavigationElements();
                        applyRTLStyles();
                    }, 300);

                    // Try again after Svelte might have settled
                    setTimeout(() => {
                        forceRTLOnTextCard();
                        protectNavigationElements();
                        applyRTLStyles();
                    }, 1000);

                    // Final attempt after everything should be loaded
                    setTimeout(() => {
                        forceRTLOnTextCard();
                        protectNavigationElements();
                        applyRTLStyles();
                        console.log("Final RTL setup complete");
                    }, 2000);
                }

                // Set up mutation observer for dynamic content
                const observer = new MutationObserver((mutations) => {
                    mutations.forEach((mutation) => {
                        mutation.addedNodes.forEach((node) => {
                            if (node.nodeType === 1) {
                                applyRTLToElement(node);

                                // If this looks like a text card, force RTL on it
                                if (node.matches('.text-card, .floating-container') ||
                                    node.querySelector('.text-card, .floating-container')) {
                                    setTimeout(() => {
                                        forceRTLOnTextCard();
                                        protectNavigationElements();
                                    }, 50);
                                }

                                // Check for navigation elements
                                if (node.matches('.navigation-footer, .nav-section') ||
                                    node.querySelector('.navigation-footer, .nav-section')) {
                                    setTimeout(protectNavigationElements, 50);
                                }
                            }
                        });
                    });

                    // Always re-apply RTL and protect navigation after mutations
                    setTimeout(() => {
                        forceRTLOnTextCard();
                        protectNavigationElements();
                    }, 100);
                });

                // Start the RTL system
                initialRTLSetup();

                // Start observing
                observer.observe(document.body, {
                    childList: true,
                    subtree: true,
                    attributes: false,
                    characterData: false
                });

                // Also observe the entire document for any changes
                observer.observe(document.documentElement, {
                    childList: true,
                    subtree: true
                });

                console.log("RTL controller initialized and observing");
            }

            // Fallback: If Svelte initialization fails, try to initialize after DOM is loaded
            if (document.readyState === 'loading') {
                document.addEventListener('DOMContentLoaded', () => {
                    setTimeout(initRTLController, 1000);
                });
            }
        </script>








































    </div>
</body>

</html>